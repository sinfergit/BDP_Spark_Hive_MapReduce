{"cells":[{"cell_type":"markdown","metadata":{},"source":["![test](files/tables/header.png)"]},{"cell_type":"markdown","metadata":{},"source":["####CMM705 Big Data Programming Coursework (Sep 2019)"]},{"cell_type":"markdown","metadata":{},"source":["## Airbnb Singapore Machine Learning Model\n\nBinary classification using pyspark and mllib libiries to predict neigbourhood group based on the latitute and longitde features. All the string columns has converted into vectors"]},{"cell_type":"markdown","metadata":{},"source":["#### 01. Retrieving the data from csv"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: string (nullable = true)\n-- name: string (nullable = true)\n-- host_id: string (nullable = true)\n-- host_name: string (nullable = true)\n-- neighbourhood_group: string (nullable = true)\n-- neighbourhood: string (nullable = true)\n-- latitude: double (nullable = true)\n-- longitude: string (nullable = true)\n-- room_type: string (nullable = true)\n-- price: integer (nullable = true)\n-- minimum_nights: integer (nullable = true)\n-- number_of_reviews: string (nullable = true)\n-- last_review: string (nullable = true)\n-- reviews_per_month: double (nullable = true)\n-- calculated_host_listings_count: integer (nullable = true)\n-- availability_365: integer (nullable = true)\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n","df = spark.read.csv('/FileStore/tables/listingsoriginal.csv', header = True, inferSchema = True)\n","df.printSchema()\n","\n","totalCount = df.count()"]},{"cell_type":"markdown","metadata":{},"source":["**Input variables:** Lat, Long\n**Output variable:** Neigbourhood group"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"evalue":"Error: Jupyter cannot be started. Error attempting to locate jupyter: Error: Module 'notebook' not installed.","output_type":"error"}],"source":["# select input variables and output variables only\n","df = df.select('latitude','longitude', 'neighbourhood_group')\n","cols = df.columns\n","df.printSchema()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["# convert str to double\ndf = df.withColumn('latitude',df['latitude'].cast(\"double\")).withColumn('longitude',df['longitude'].cast(\"double\"))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: 26</div>"]},"metadata":{},"output_type":"display_data"}],"source":["#drop null values\ndf = df.dropna()\nnullValuesCount = totalCount - df.count()\nnullValuesCount"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["display(df)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>neighbourhood_group</th><th>count</th></tr></thead><tbody><tr><td>West Region</td><td>539</td></tr><tr><td>Central Region</td><td>6301</td></tr><tr><td>North Region</td><td>203</td></tr><tr><td>East Region</td><td>508</td></tr><tr><td>North-East Region</td><td>344</td></tr></tbody></table></div>"]},"metadata":{},"output_type":"display_data"}],"source":["grouping_data = df.groupby('neighbourhood_group').count()\ndisplay(grouping_data)"]},{"cell_type":"markdown","metadata":{},"source":["#### 02. Preparing Data for Machine Learning"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n\nstages = []\n\nlabel_stringIdx = StringIndexer(inputCol = 'neighbourhood_group', outputCol = 'label')\nstages += [label_stringIdx]\n\nassemblerInputs = ['latitude', 'longitude']\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- label: double (nullable = false)\n-- features: vector (nullable = true)\n-- latitude: double (nullable = true)\n-- longitude: double (nullable = true)\n-- neighbourhood_group: string (nullable = true)\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["# Pipeline\nfrom pyspark.ml import Pipeline\n\npipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(df)\ndf = pipelineModel.transform(df)\nselectedCols = ['label', 'features'] + cols\ndf = df.select(selectedCols)\ndf.printSchema()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>label</th>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>features</th>\n      <td>[1.44255, 103.7958]</td>\n      <td>[1.33235, 103.78521]</td>\n      <td>[1.44246, 103.79667]</td>\n      <td>[1.34541, 103.95712]</td>\n      <td>[1.34567, 103.95963]</td>\n    </tr>\n    <tr>\n      <th>latitude</th>\n      <td>1.44255</td>\n      <td>1.33235</td>\n      <td>1.44246</td>\n      <td>1.34541</td>\n      <td>1.34567</td>\n    </tr>\n    <tr>\n      <th>longitude</th>\n      <td>103.796</td>\n      <td>103.785</td>\n      <td>103.797</td>\n      <td>103.957</td>\n      <td>103.96</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_group</th>\n      <td>North Region</td>\n      <td>Central Region</td>\n      <td>North Region</td>\n      <td>East Region</td>\n      <td>East Region</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\npd.DataFrame(df.take(5), columns=df.columns).transpose()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 6310\nTest Dataset Count: 1585\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["# split data for testing and training\n\ntrain, test = df.randomSplit([0.8, 0.2], seed = 2018)\nprint(\"Training Dataset Count: \" + str(train.count()))\nprint(\"Test Dataset Count: \" + str(test.count()))"]},{"cell_type":"markdown","metadata":{},"source":["#### 03. Use the Decision Tree Classifier"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+---------+-----+--------------------+----------+--------------------+\nlatitude|longitude|label|       rawPrediction|prediction|         probability|\n+--------+---------+-----+--------------------+----------+--------------------+\n 1.25284|103.82225|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.26624|103.81097|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.26675|103.81219|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.26814|103.81203|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.26863| 103.8239|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.26983|103.81331|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.27173|103.82232|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.27234|103.83224|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.27237|103.83233|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n 1.27239|103.83419|  0.0|[4935.0,19.0,26.0...|       0.0|[0.99096385542168...|\n+--------+---------+-----+--------------------+----------+--------------------+\nonly showing top 10 rows\n\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\ndtModel = dt.fit(train)\npredictions = dtModel.transform(test)\npredictions.select('latitude', 'longitude', 'label', 'rawPrediction', 'prediction', 'probability').show(10)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.3278602373507068\n</div>"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"]},{"cell_type":"markdown","metadata":{},"source":["#### 03. Use the Logistic Regression Model"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression\n\n# We can also use the multinomial family for binary classification\nmlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n\n# Fit the model\nmlrModel = mlr.fit(train)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Print the coefficients and intercepts for logistic regression with multinomial family\nprint(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\nprint(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Make predictions on the test set\n\npredictions = mlrModel.transform(test)\npredictions.select('latitude', 'longitude', 'label', 'rawPrediction', 'prediction', 'probability').show(10)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#Evaluate our Logistic Regression model.\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', evaluator.evaluate(predictions))"]}],"metadata":{"name":"CMM705-Big-Data-Programming-ML","notebookId":1882503201949296},"nbformat":4,"nbformat_minor":0}